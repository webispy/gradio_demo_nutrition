from typing import Annotated, TypedDict, Literal, List, Generator, Tuple
import ast
import re
import time
from pprint import pprint

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.vectorstores import InMemoryVectorStore

from langchain_community.tools import QuerySQLDatabaseTool
from langchain_community.utilities import SQLDatabase
from langchain.agents.agent_toolkits import create_retriever_tool

from langchain.chains import create_sql_query_chain
from langchain.chains.sql_database.prompt import SQLITE_PROMPT

from langgraph.graph import START, END, StateGraph 

import gradio as gr
import logging
import sys

##################################################################
# í™˜ê²½ ì„¤ì • / ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
##################################################################
from dotenv import load_dotenv
load_dotenv()

logger = logging.getLogger("nutrition_assistant")
logger.setLevel(logging.INFO)
logger.propagate = False

# --- levelname í•œê¸€ì ë³€í™˜ìš© ---
LEVEL_MAP = {
    "DEBUG": "D",
    "INFO": "I",
    "WARNING": "W",
    "ERROR": "E",
    "CRITICAL": "F",
}

class AdbStyleFormatter(logging.Formatter):
    def format(self, record):
        record.levelshort = LEVEL_MAP.get(record.levelname, record.levelname[0])
        record.pid = f"{record.process:5d}"
        record.tid = f"{record.thread:5d}"
        return super().format(record)

formatter = AdbStyleFormatter(
    fmt="%(asctime)s.%(msecs)03d %(pid)s %(tid)s %(levelshort)s %(name)s: %(message)s",
    datefmt="%m-%d %H:%M:%S"
)

if not logger.handlers:  # í•¸ë“¤ëŸ¬ ì¤‘ë³µ ì¶”ê°€ ë°©ì§€
    h = logging.StreamHandler(sys.stdout)
    h.setFormatter(formatter)
    logger.addHandler(h)

db = SQLDatabase.from_uri("sqlite:///data/nutrition_data.db")

# ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” ëª©ë¡ ì¶œë ¥
tables = db.get_usable_table_names()
logger.info(f"Available tables in the database: {tables}")

columns_result = db.run("SELECT c.name FROM PRAGMA_TABLE_INFO('nutrition_data') c")
logger.info(f"Columns in 'nutrition_data' table: {columns_result}")

data_count = db.run("SELECT COUNT(*) FROM nutrition_data")
logger.info(f"Total records in 'nutrition_data' table: {data_count}")

execute_query_tool = QuerySQLDatabaseTool(db=db)

##################################################################
# ìƒíƒœ ì •ë³´ íƒ€ì… ì •ì˜
##################################################################

# ìƒíƒœ ì •ì˜
class NutritionState(TypedDict):
    question: str
    query: str
    score: float
    result: str
    answer: str
    current_node: str
    status: str


# SQL ì¿¼ë¦¬ ìƒì„± Structured Output
class QueryOutput(TypedDict):
    """Generated SQL query."""
    query: Annotated[str, ..., "Syntactically valid SQL query."]


# ìƒì„±ëœ ì¿¼ë¦¬ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ Structured Output    
class EvaluateOutput(TypedDict):
    """Evaluate SQL query."""
    score: float
    columns: List[str]
    


##################################################################
# ëª¨ë¸ ë° ì²´ì¸ ìƒì„±
##################################################################
llm = ChatOpenAI(model="gpt-4.1-mini")

structured_query_llm = llm.with_structured_output(QueryOutput)
structured_evaluate_llm = llm.with_structured_output(EvaluateOutput)

# SQL ì¿¼ë¦¬ ìƒì„± chain (ìµœëŒ€ 10ê°œì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬ ìƒì„±)
gpt_sql = create_sql_query_chain(llm=llm, db=db, k=10, prompt=SQLITE_PROMPT)


# ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°±
status_callback = None

def set_status_callback(callback):
    """ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜ ì„¤ì •"""
    global status_callback
    status_callback = callback

def update_status(node_name: str, description: str, progress: int):
    """ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜"""
    if status_callback:
        status_callback(node_name, description, progress)


##################################################################
# SQL ì¿¼ë¦¬ ìƒì„±
##################################################################

def write_query(state: NutritionState) -> NutritionState:
    """Generate SQL query to fetch information."""
    update_status("write_query", "ğŸ” ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...", 25)
    
    logger.info("<write_query> Question: %s", state["question"])
    prompt = gpt_sql.invoke({"question": state["question"]})
    result = structured_query_llm.invoke(prompt)    
    logger.info("<write_query> Generated query: %s", result["query"])
    
    return {
        **state,
        "query": result["query"],
        "current_node": "write_query",
        "status": "SQL ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ"
    }

def evaluate_query(state: NutritionState) -> NutritionState:
    """Evaluate SQL query."""
    update_status("evaluate_query", "ğŸ“Š ìƒì„±ëœ ì¿¼ë¦¬ì˜ ì •í•©ì„±ì„ í‰ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤...", 50)
    
    # ì‹¤ì œ êµ¬í˜„ ë¶€ë¶„ (ì˜ˆì‹œ)
    prompt = f"""
        ì•„ë˜ ì§ˆë¬¸ê³¼ ì¿¼ë¦¬ì˜ ì •í•©ì„±ì— ëŒ€í•´ í‰ê°€í•´ì£¼ì„¸ìš”. ì ìˆ˜(0~1)ë¡œë§Œ í‰ê°€í•´ì£¼ê³  ì‚¬ìš©ëœ ì»¬ëŸ¼ ì´ë¦„ì„ ë°˜í™˜í•´ì£¼ì„¸ìš”.

        Question: {state["question"]}
        SQLQuery: {state["query"]}
        """
    
    logger.info("<evaluate_query> Prompt: %s", prompt)
    result = structured_evaluate_llm.invoke(prompt)
    logger.info("<evaluate_query> Result: %s", result)

    columns = result["columns"]
    for column in columns:
        if column not in db.get_table_info():
            logger.error(f"ì‚¬ìš©ëœ ì»¬ëŸ¼ {column}ì´ ì‹¤ì œ í…Œì´ë¸”ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return {
                **state,
                "score": 0,
                "current_node": "evaluate_query",
                "status": "ì¿¼ë¦¬ í‰ê°€ ì‹¤íŒ¨ - ì˜ëª»ëœ ì»¬ëŸ¼"
            }

    return {
        **state,
        "score": result["score"],
        "current_node": "evaluate_query",
        "status": "ì¿¼ë¦¬ í‰ê°€ ì™„ë£Œ"
    }

def decide_next_step(state: NutritionState) -> Literal["execute_query", "unsupported_data"]:
    """ì ìˆ˜ê°€ 0.3 ì´ìƒì´ë©´ ì¿¼ë¦¬ ì‹¤í–‰, ì•„ë‹ˆë©´ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°"""
    logger.info("<decide_next_step> score: %s", state['score'])
    if state["score"] > 0.3:
        return "execute_query"
    else:
        return "unsupported_data"

def execute_query(state: NutritionState) -> NutritionState:
    """SQLì¿¼ë¦¬ ì‹¤í–‰"""
    update_status("execute_query", "ğŸ§¬ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì˜ì–‘ì†Œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...", 75)
    
    logger.info("<execute_query> Executing query: %s", state["query"])
    result = execute_query_tool.invoke(state["query"])
    logger.info("<execute_query> Query result: %s", result)

    return {
        **state,
        "result": result,
        "current_node": "execute_query",
        "status": "ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ"
    }

def generate_answer(state: NutritionState) -> NutritionState:
    """ì£¼ì–´ì§„ ì§ˆë¬¸, ì¿¼ë¦¬, ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
    update_status("generate_answer", "âš¡ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...", 90)
    
    prompt = (
        "Given the following user question, corresponding SQL query, "
        "and SQL result, answer the user question.\n\n"
        f'Question: {state["question"]}\n'
        f'SQL Query: {state["query"]}\n'
        f'SQL Result: {state["result"]}'
    )
    
    logger.info("<generate_answer> Prompt: %s", prompt)
    response = llm.invoke(prompt)
    logger.info("<generate_answer> Generated answer: %s", response.content)

    return {
        **state,
        "answer": response.content,
        "current_node": "generate_answer",
        "status": "ë‹µë³€ ìƒì„± ì™„ë£Œ"
    }

def unsupported_data(state: NutritionState) -> NutritionState:
    """ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì— ëŒ€í•œ ì‘ë‹µ"""
    update_status("unsupported_data", "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…ë‹ˆë‹¤", 100)
    
    logger.info("<unsupported_data> Unsupported data for question: %s", state["question"])

    return {
        **state,
        "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "current_node": "unsupported_data",
        "status": "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°"
    }

##################################################################
# ìƒíƒœ ê·¸ë˜í”„ ìƒì„±
##################################################################

def create_graph():
    """StateGraph ìƒì„±"""
    graph_builder = StateGraph(NutritionState)

    graph_builder.add_node("write_query", write_query)
    graph_builder.add_node("evaluate_query", evaluate_query)
    graph_builder.add_node("execute_query", execute_query)
    graph_builder.add_node("generate_answer", generate_answer)
    graph_builder.add_node("unsupported_data", unsupported_data)

    graph_builder.add_edge(START, "write_query")
    graph_builder.add_edge("write_query", "evaluate_query")

    graph_builder.add_conditional_edges(
        "evaluate_query",
        decide_next_step
    )

    graph_builder.add_edge("execute_query", "generate_answer")
    graph_builder.add_edge("generate_answer", END)
    graph_builder.add_edge("unsupported_data", END)

    return graph_builder.compile()

##################################################################
# Gradio ì¸í„°í˜ì´ìŠ¤ - ì‹¤ì‹œê°„ ìƒíƒœ í‘œì‹œ
##################################################################

def nutrition_assistant_with_status(question: str) -> Generator[Tuple[str, str], None, None]:
    """ì‹¤ì‹œê°„ ìƒíƒœ ì—…ë°ì´íŠ¸ê°€ í¬í•¨ëœ ì˜ì–‘ì†Œ ë¶„ì„ í•¨ìˆ˜"""
    
    if not question.strip():
        yield "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "âŒ ë¹ˆ ì§ˆë¬¸ì…ë‹ˆë‹¤."
        return
    
    # í˜„ì¬ ìƒíƒœë¥¼ ì €ì¥í•  ë³€ìˆ˜ë“¤
    current_status = {"node": "", "description": "", "progress": 0}
    
    def status_update_callback(node_name: str, description: str, progress: int):
        """ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°±"""
        current_status.update({
            "node": node_name,
            "description": description,
            "progress": progress
        })
    
    # ì½œë°± ì„¤ì •
    set_status_callback(status_update_callback)
    
    try:
        # ê·¸ë˜í”„ ìƒì„± ë° ì´ˆê¸° ìƒíƒœ ì„¤ì •
        graph = create_graph()
        initial_state = {
            "question": question,
            "query": "",
            "score": 0.0,
            "result": "",
            "answer": "",
            "current_node": "",
            "status": ""
        }
        
        # ê·¸ë˜í”„ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
        final_state = None
        
        for state in graph.stream(initial_state):
            # stateëŠ” {node_name: updated_state} í˜•íƒœ
            node_name = list(state.keys())[0]
            node_state = state[node_name]
            final_state = node_state
            
            # ì§„í–‰ë¥  ê³„ì‚°
            progress = current_status["progress"]
            progress_bar = "â–ˆ" * (progress // 25) + "â–‘" * (4 - progress // 25)
            
            # ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ
            temp_result = f"""
### ğŸ”„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...

**í˜„ì¬ ë‹¨ê³„:** {current_status["description"]}

**ìƒì„±ëœ SQL ì¿¼ë¦¬:** 
```sql
{node_state.get('query', 'N/A')}
```

**í‰ê°€ ì ìˆ˜:** {node_state.get('score', 'N/A')}

**ì§„í–‰ ìƒí™©:**
```
{progress_bar} {progress}%
```

ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...
            """
            
            status_text = f"{current_status['description']}\n\nì§„í–‰ë¥ : [{progress_bar}] {progress}%"
            
            yield temp_result, status_text
#            time.sleep(0.5)  # ì‹œê°ì  íš¨ê³¼
        
        # ìµœì¢… ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
        update_status("completed", "âœ… ë¶„ì„ ì™„ë£Œ!", 100)
        
        # ìµœì¢… ê²°ê³¼ ìƒì„±
        if final_state:
            final_result = f"""
### ğŸ ì˜ì–‘ì†Œ ë¶„ì„ ê²°ê³¼

**ì§ˆë¬¸:** {question}

**ìƒì„±ëœ SQL ì¿¼ë¦¬:**
```sql
{final_state.get('query', 'N/A')}
```

**í‰ê°€ ì ìˆ˜:** {final_state.get('score', 'N/A')}

**ê²€ìƒ‰ ê²°ê³¼:**
```
{final_state.get('result', 'N/A')}
```

**ìµœì¢… ë‹µë³€:**
{final_state.get('answer', 'ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')}

---
âœ… **ë¶„ì„ ì™„ë£Œ** | êµ­ê°€í‘œì¤€ ì‹í’ˆì„±ë¶„í‘œ ê¸°ì¤€
            """
        else:
            final_result = """
### âŒ ì²˜ë¦¬ ì‹¤íŒ¨

ë¶„ì„ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
            """
        
        final_status = "âœ… ë¶„ì„ ì™„ë£Œ!"
        yield final_result, final_status
        
    except Exception as e:
        error_result = f"""
### âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ

**ì˜¤ë¥˜ ë©”ì‹œì§€:** {str(e)}

**ì§ˆë¬¸:** {question}

ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ë‹¤ë¥¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
        """
        
        yield error_result, f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    finally:
        # ì½œë°± ì •ë¦¬
        set_status_callback(None)

##################################################################
# Gradio ì¸í„°í˜ì´ìŠ¤
##################################################################

def create_gradio_interface():
    """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    with gr.Blocks(
        title="ğŸ ì‹í’ˆì„±ë¶„ ì˜ì–‘ì†Œ ì¡°íšŒ ì–´ì‹œìŠ¤í„´íŠ¸",
        theme=gr.themes.Soft()
    ) as demo:
        
        gr.Markdown("""
        # ğŸ ì‹í’ˆì„±ë¶„ ì˜ì–‘ì†Œ ì¡°íšŒ ì–´ì‹œìŠ¤í„´íŠ¸
        
        êµ­ê°€ í‘œì¤€ ì‹í’ˆ ì„±ë¶„ ê¸°ë°˜ ì˜ì–‘ì†Œ ë¶„ì„ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.  
        ìì—°ì–´ ì§ˆë¬¸ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì •í™•í•œ ì˜ì–‘ì†Œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                question_input = gr.Textbox(
                    label="ğŸ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
                    placeholder="ì˜ˆ: ë¹„íƒ€ë¯¼Cê°€ ê°€ì¥ ë§ì€ ì‹í’ˆ 5ê°œëŠ”?",
                    lines=4
                )
                
                analyze_btn = gr.Button(
                    "âš¡ ì˜ì–‘ì†Œ ë¶„ì„í•˜ê¸°", 
                    variant="primary", 
                    size="lg"
                )
                
                # ì‹¤ì‹œê°„ ìƒíƒœ í‘œì‹œ
                status_display = gr.Textbox(
                    label="ğŸ“Š ì²˜ë¦¬ ìƒíƒœ",
                    value="ëŒ€ê¸° ì¤‘... ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ë¶„ì„ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.",
                    interactive=False,
                    lines=3
                )
            
            with gr.Column(scale=2):
                result_output = gr.Markdown(
                    value="""
                    ### ğŸ“‹ ë¶„ì„ ê²°ê³¼
                    
                    ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  **ë¶„ì„í•˜ê¸°** ë²„íŠ¼ì„ í´ë¦­í•˜ë©´  
                    ì‹¤ì‹œê°„ìœ¼ë¡œ AI ì—ì´ì „íŠ¸ì˜ ì²˜ë¦¬ ê³¼ì •ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    
                    **ì²˜ë¦¬ ë‹¨ê³„:**
                    1. ğŸ” ì§ˆë¬¸ ë¶„ì„ ë° SQL ì¿¼ë¦¬ ìƒì„±
                    2. ğŸ“Š ì¿¼ë¦¬ ì •í•©ì„± í‰ê°€  
                    3. ğŸ§¬ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
                    4. âš¡ ë‹µë³€ ìƒì„±
                    """,
                    container=True
                )
        
        # ì˜ˆì‹œ ì§ˆë¬¸
        gr.Markdown("### ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸ (í´ë¦­í•˜ë©´ ìë™ ì…ë ¥)")
        gr.Examples(
            examples=[
                "ì¡°ë¦¬ê°€ê³µì‹í’ˆ ì¤‘ ì¹¼ë¡œë¦¬ê°€ ê°€ì¥ ë†’ì€ ì‹í’ˆ 5ê°œëŠ”?",
                "ì§œì¥ë¼ë©´ê³¼ ë³¶ìŒë¼ë©´ì˜ ë‹¹ë¥˜ í•¨ëŸ‰ê³¼ ì—ë„ˆì§€ í•¨ëŸ‰ì€?",
                "ì—°ìë°¥ì— ë“¤ì–´ìˆëŠ” ëª¨ë“  ì˜ì–‘ì†ŒëŠ”?",
                "ë¹„íƒ€ë¯¼Cê°€ ê°€ì¥ ë§ì€ ì‹í’ˆ 5ê°œëŠ”?",
                "ì˜¤ë©”ê°€3ê°€ ê°€ì¥ ë§ì€ ì‹í’ˆ 5ê°œëŠ”?",
                "ìƒìœ„ 5ê°œ ìš”ì˜¤ë“œê°€ ë†’ì€ ì‹í’ˆì€?",
                "ì¹¼ìŠ˜ì´ í’ë¶€í•œ ìœ ì œí’ˆ ì¢…ë¥˜ëŠ”?",
                "ì±„ì†Œë¥˜ ì¤‘ ì‹ì´ì„¬ìœ ê°€ ê°€ì¥ ë§ì€ ì‹í’ˆì€?",
                "í†µí’ì— ê°€ì¥ ì•ˆì¢‹ì€ ì‹í’ˆì€?"
            ],
            inputs=question_input
        )
        
        # ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ - Generator í•¨ìˆ˜ ì—°ê²°
        analyze_btn.click(
            fn=nutrition_assistant_with_status,
            inputs=question_input,
            outputs=[result_output, status_display]
        )
        
        # Enter í‚¤ ì§€ì›
        question_input.submit(
            fn=nutrition_assistant_with_status,
            inputs=question_input,
            outputs=[result_output, status_display]
        )
    
    return demo

if __name__ == "__main__":
    demo = create_gradio_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
